[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "cases simulation study",
    "section": "",
    "text": "Overview\nWestphal & Zapf, 2021 investigated different multiple comparison procedures (MCPs) for a certain type of analyis (e.g.) relevant in diagnostic accuracy studies, the so-called co-primary endpoint analysis.\nThe R package cases contains user-friendly implementations of these MCPs.\nThis R project cases_simstudy contains a reproducible description of the implementation and results of this simulation study in form of a quarto book. The GitHub repository for this project is github.com/maxwestphal/cases_simstudy\nThis report is not meant to a standalone resource but rather should be read in addition to the main paper.\nIn addition, the R script cases_simstudy_paper_figures.R allows to reproduce the figures in the main paper."
  },
  {
    "objectID": "1_implementation.html",
    "href": "1_implementation.html",
    "title": "1  Implementation",
    "section": "",
    "text": "The cases package provides the direct implementation all the multiple comparison procedures under investigation.\nThe simulation study was conducted with the R package batchtools.\nFor generation of the synthetic binary data, the bindata package was used among others.\nVersion control of employed dependencies is handled via the renv package."
  },
  {
    "objectID": "2_analysis.html",
    "href": "2_analysis.html",
    "title": "2  Results",
    "section": "",
    "text": "Code\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(ggplot2)\nFor local reproduction, the input directory potentially needs to be adapted!"
  },
  {
    "objectID": "1_implementation.html#reproduction",
    "href": "1_implementation.html#reproduction",
    "title": "1  Implementation",
    "section": "1.2 Reproduction",
    "text": "1.2 Reproduction\nThe required packages can be installed/loaded via\n\n\nCode\ninstall.packages(\"renv\")\nrenv::restore()\n\n\nTo reproduce the the simulation study two R scripts need to be executed\n\nR/cases_simstudy_lfc.R,\nR/cases_simstudy_roc.R\n\nIn particular for the first run, it is required to setup the directories in the PREPARATION section in each file, in particular the main.dir.\nThe simulation (problem, algorithm) parameters are specified as in the main paper."
  },
  {
    "objectID": "1_implementation.html#info",
    "href": "1_implementation.html#info",
    "title": "1  Implementation",
    "section": "1.3 Info",
    "text": "1.3 Info\nThe simulation study has been conducted (originally) with the following system specification.\n\n\nCode\nR.Version()\n\n\n$platform\n[1] \"x86_64-w64-mingw32\"\n\n$arch\n[1] \"x86_64\"\n\n$os\n[1] \"mingw32\"\n\n$crt\n[1] \"ucrt\"\n\n$system\n[1] \"x86_64, mingw32\"\n\n$status\n[1] \"\"\n\n$major\n[1] \"4\"\n\n$minor\n[1] \"2.1\"\n\n$year\n[1] \"2022\"\n\n$month\n[1] \"06\"\n\n$day\n[1] \"23\"\n\n$`svn rev`\n[1] \"82513\"\n\n$language\n[1] \"R\"\n\n$version.string\n[1] \"R version 4.2.1 (2022-06-23 ucrt)\"\n\n$nickname\n[1] \"Funny-Looking Kid\""
  },
  {
    "objectID": "2_analysis.html#simulation-study-1-lfc-setting",
    "href": "2_analysis.html#simulation-study-1-lfc-setting",
    "title": "2  Results",
    "section": "2.1 Simulation study 1: LFC setting",
    "text": "2.1 Simulation study 1: LFC setting\n\n2.1.1 Main results\n\n\nCode\ndata_lfc &lt;- readr::read_csv2(file.path(in.dir, \"cases_SIM_LFC.csv\"))\n\n\nℹ Using \"','\" as decimal and \"'.'\" as grouping mark. Use `read_delim()` for more control.\n\n\nRows: 5600000 Columns: 61\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (10): problem, algorithm, cortype, contrast, alternative, adjustment, tr...\ndbl (50): job.id, nrep, n, prev, m, se, sp, L, rhose, rhosp, benchmark, alph...\nlgl  (1): random\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\ndata_lfc &lt;- data_lfc %&gt;%\n  mutate(Adjustment = recode_factor(\n    interaction(adjustment, pars),\n    \"none.list()\" = \"none\",\n    \"bonferroni.list()\"=\"Bonferroni\", \n    \"maxt.list()\" = \"maxT\",\n    \"mbeta.list()\" = \"mBeta\",\n    \"bootstrap.list(type='wild')\" = \"Bootstrap (wild)\",\n    \"bootstrap.list()\" = \"Bootstrap (pairs)\")\n  )\n\ndim(data_lfc)\n\n\n[1] 5600000      62\n\n\n\n\nCode\ndata_lfc &lt;- data_lfc %&gt;% \n  filter(cortype == \"equi\") %&gt;% \n  filter(rhose == 0.5) %&gt;%\n  filter(transformation == \"none\") \n\ndim(data_lfc)\n\n\n[1] 2400000      62\n\n\n\n\nCode\ndata_lfc %&gt;% \n  filter(n&lt;1000, prev==0.25, se==0.8, m==10) %&gt;%\n  group_by(Adjustment, n, prev, se, m) %&gt;%\n  summarize(nsim=n(), rr = mean(`0` &gt; 0)) %&gt;%\n  ggplot(aes(n, rr, col=Adjustment, fill=Adjustment, pch=Adjustment))+\n  geom_point(size=6, alpha=0.6) +\n  geom_line(size=2, alpha=0.6) +\n  xlab(\"Total sample size\") +\n  ylab(\"FWER\") +\n  scale_shape_manual(values = c(21, 22, 24, 25, 23, 23)) +\n  geom_hline(yintercept=0.025, col=\"red\", lwd=2, lty=2, alpha=0.75) +\n  owntheme\n\n\n`summarise()` has grouped output by 'Adjustment', 'n', 'prev', 'se'. You can\noverride using the `.groups` argument.\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\nCode\ndata_lfc %&gt;% \n  filter(n&lt;1000, prev==0.25, se==0.8, m==10) %&gt;%\n  group_by(Adjustment, n, prev, se, m) %&gt;%\n  summarize(nsim=n(), rr = mean(`0.05` &gt; 0)) %&gt;%\n  ggplot(aes(n, rr, col=Adjustment, fill=Adjustment, pch=Adjustment)) +\n  geom_point(size=6, alpha=0.6) +\n  geom_line(size=2, alpha=0.6) +\n  xlab(\"Total sample size\") +\n  ylab(\"Power\") + \n  scale_shape_manual(values = c(21, 22, 24, 25, 23, 23)) +\n  owntheme\n\n\n`summarise()` has grouped output by 'Adjustment', 'n', 'prev', 'se'. You can\noverride using the `.groups` argument.\n\n\n\n\n\n\n\n2.1.2 Sensitivity analyses\n\n\nCode\ndata_lfc %&gt;% \n  filter(n&lt;1000) %&gt;%\n  group_by(Adjustment, n, prev, se, m) %&gt;%\n  summarize(nsim=n(), rr = mean(`0` &gt; 0)) %&gt;%\n  ggplot(aes(n, rr, col=Adjustment, fill=Adjustment, pch=Adjustment))+\n  geom_point(size=6, alpha=0.6) +\n  geom_line(size=2, alpha=0.6) +\n  xlab(\"Total sample size\") +\n  ylab(\"FWER\") +\n  scale_shape_manual(values = c(21, 22, 24, 25, 23, 23)) +\n  geom_hline(yintercept=0.025, col=\"red\", lwd=2, lty=2, alpha=0.75) +\n  owntheme +\n  facet_wrap(prev+se ~ m, ncol=2, \n             labeller = label_bquote(\"prev = \" ~ .(prev) * \", \" * \"se = \" ~ .(se) * \", \" * \"m = \" ~ .(m)))\n\n\n`summarise()` has grouped output by 'Adjustment', 'n', 'prev', 'se'. You can\noverride using the `.groups` argument.\n\n\n\n\n\n\n\nCode\ndata_lfc %&gt;% \n  filter(n&lt;1000) %&gt;%\n  group_by(Adjustment, n, prev, se, m) %&gt;%\n  summarize(nsim=n(), rr = mean(`0.05` &gt; 0)) %&gt;%\n  ggplot(aes(n, rr, col=Adjustment, fill=Adjustment, pch=Adjustment)) +\n  geom_point(size=6, alpha=0.6) +\n  geom_line(size=2, alpha=0.6) +\n  xlab(\"Total sample size\") +\n  ylab(\"Power\") + \n  scale_shape_manual(values = c(21, 22, 24, 25, 23, 23)) +\n  owntheme +\n  facet_wrap(prev+se ~ m, ncol=2, \n             labeller = label_bquote(\"prev = \" ~ .(prev) * \", \" * \"se = \" ~ .(se) * \", \" * \"m = \" ~ .(m)))\n\n\n`summarise()` has grouped output by 'Adjustment', 'n', 'prev', 'se'. You can\noverride using the `.groups` argument.\n\n\n\n\n\n\n\nCode\ndata_lfc %&gt;% \n  filter(n&lt;1000) %&gt;%\n  group_by(Adjustment, n, prev, se, m) %&gt;%\n  summarize(nsim=n(), rr = mean(`0.1` &gt; 0)) %&gt;%\n  ggplot(aes(n, rr, col=Adjustment, fill=Adjustment, pch=Adjustment)) +\n  geom_point(size=6, alpha=0.6) +\n  geom_line(size=2, alpha=0.6) +\n  xlab(\"Total sample size\") +\n  ylab(\"Power\") + \n  scale_shape_manual(values = c(21, 22, 24, 25, 23, 23)) +\n  owntheme +\n  facet_wrap(prev+se ~ m, ncol=2, \n             labeller = label_bquote(\"prev = \" ~ .(prev) * \", \" * \"se = \" ~ .(se) * \", \" * \"m = \" ~ .(m)))\n\n\n`summarise()` has grouped output by 'Adjustment', 'n', 'prev', 'se'. You can\noverride using the `.groups` argument."
  },
  {
    "objectID": "2_analysis.html#simulation-study-2-roc-setting",
    "href": "2_analysis.html#simulation-study-2-roc-setting",
    "title": "2  Results",
    "section": "2.2 Simulation study 2: ROC setting",
    "text": "2.2 Simulation study 2: ROC setting\n\n2.2.1 Main results\n\n\nCode\ndata_roc &lt;- readr::read_csv2(file.path(in.dir, \"cases_SIM_ROC.csv\"))\n\n\nℹ Using \"','\" as decimal and \"'.'\" as grouping mark. Use `read_delim()` for more control.\n\n\nRows: 8400000 Columns: 61\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (10): problem, algorithm, auc, contrast, alternative, adjustment, transf...\ndbl (50): job.id, nrep, n, prev, m, rhose, e, k, delta, rhosp, benchmark, al...\nlgl  (1): random\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\ndata_roc &lt;- data_roc %&gt;%\n  mutate(Adjustment = recode_factor(\n    interaction(adjustment, pars),\n    \"none.list()\" = \"none\",\n    \"bonferroni.list()\"=\"Bonferroni\", \n    \"maxt.list()\" = \"maxT\",\n    \"mbeta.list()\" = \"mBeta\",\n    \"bootstrap.list(type='wild')\" = \"Bootstrap (wild)\",\n    \"bootstrap.list()\" = \"Bootstrap (pairs)\")\n  )\n\ndim(data_roc)\n\n\n[1] 8400000      62\n\n\n\n\nCode\ndata_roc &lt;- data_roc %&gt;% \n  filter(rhose == 0.5) %&gt;%\n  filter(auc == \"seq(0.85, 0.90, length.out = 5)\") %&gt;% \n  filter(transformation == \"none\") \n\ndim(data_roc)\n\n\n[1] 1200000      62\n\n\n\n\nCode\ndata_roc %&gt;% \n  filter(n&lt;1000, prev==0.25, m==10) %&gt;%\n  group_by(Adjustment, n, prev, m) %&gt;%\n  summarize(nsim=n(), rr = mean(`0` &gt; 0)) %&gt;%\n  ggplot(aes(n, rr, col=Adjustment, fill=Adjustment, pch=Adjustment))+\n  geom_point(size=6, alpha=0.6) +\n  geom_line(size=2, alpha=0.6) +\n  xlab(\"Total sample size\") +\n  ylab(\"FWER\") +\n  scale_shape_manual(values = c(21, 22, 24, 25, 23, 23)) +\n  geom_hline(yintercept=0.025, col=\"red\", lwd=2, lty=2, alpha=0.75) +\n  owntheme \n\n\n`summarise()` has grouped output by 'Adjustment', 'n', 'prev'. You can override\nusing the `.groups` argument.\n\n\n\n\n\n\n\nCode\ndata_roc %&gt;% \n  filter(n&lt;1000, prev==0.25, m==10) %&gt;%\n  group_by(Adjustment, n, prev, m) %&gt;%\n  summarize(nsim=n(), rr = mean(`0.1` &gt; 0)) %&gt;%\n  ggplot(aes(n, rr, col=Adjustment, fill=Adjustment, pch=Adjustment)) +\n  geom_point(size=6, alpha=0.6) +\n  geom_line(size=2, alpha=0.6) +\n  xlab(\"Total sample size\") +\n  ylab(\"Power\") + \n  scale_shape_manual(values = c(21, 22, 24, 25, 23, 23)) +\n  owntheme \n\n\n`summarise()` has grouped output by 'Adjustment', 'n', 'prev'. You can override\nusing the `.groups` argument.\n\n\n\n\n\n\n\n2.2.2 Sensitivity analyses\n\n\nCode\ndata_roc %&gt;% \n  filter(n&lt;1000) %&gt;%\n  group_by(Adjustment, n, prev, m) %&gt;%\n  summarize(nsim=n(), rr = mean(`0` &gt; 0)) %&gt;%\n  ggplot(aes(n, rr, col=Adjustment, fill=Adjustment, pch=Adjustment))+\n  geom_point(size=6, alpha=0.6) +\n  geom_line(size=2, alpha=0.6) +\n  xlab(\"Total sample size\") +\n  ylab(\"FWER\") +\n  scale_shape_manual(values = c(21, 22, 24, 25, 23, 23)) +\n  geom_hline(yintercept=0.025, col=\"red\", lwd=2, lty=2, alpha=0.75) +\n  owntheme +\n  facet_wrap(prev ~ m, ncol=2, \n             labeller = label_bquote(\"prev = \" ~ .(prev) * \", \" * \"m = \" ~ .(m)))\n\n\n`summarise()` has grouped output by 'Adjustment', 'n', 'prev'. You can override\nusing the `.groups` argument.\n\n\n\n\n\n\n\nCode\ndata_roc %&gt;% \n  filter(n&lt;1000) %&gt;%\n  group_by(Adjustment, n, prev, m) %&gt;%\n  summarize(nsim=n(), rr = mean(`0.1` &gt; 0)) %&gt;%\n  ggplot(aes(n, rr, col=Adjustment, fill=Adjustment, pch=Adjustment)) +\n  geom_point(size=6, alpha=0.6) +\n  geom_line(size=2, alpha=0.6) +\n  xlab(\"Total sample size\") +\n  ylab(\"Power\") + \n  scale_shape_manual(values = c(21, 22, 24, 25, 23, 23)) +\n  owntheme +\n  facet_wrap(prev ~ m, ncol=2, \n             labeller = label_bquote(\"prev = \" ~ .(prev) * \", \" * \"m = \" ~ .(m)))\n\n\n`summarise()` has grouped output by 'Adjustment', 'n', 'prev'. You can override\nusing the `.groups` argument.\n\n\n\n\n\n\n\nCode\ndata_roc %&gt;% \n  filter(n&lt;1000) %&gt;%\n  group_by(Adjustment, n, prev, m) %&gt;%\n  summarize(nsim=n(), rr = mean(`0.05` &gt; 0)) %&gt;%\n  ggplot(aes(n, rr, col=Adjustment, fill=Adjustment, pch=Adjustment)) +\n  geom_point(size=6, alpha=0.6) +\n  geom_line(size=2, alpha=0.6) +\n  xlab(\"Total sample size\") +\n  ylab(\"Power\") + \n  scale_shape_manual(values = c(21, 22, 24, 25, 23, 23)) +\n  owntheme +\n  facet_wrap(prev ~ m, ncol=2, \n             labeller = label_bquote(\"prev = \" ~ .(prev) * \", \" * \"m = \" ~ .(m)))\n\n\n`summarise()` has grouped output by 'Adjustment', 'n', 'prev'. You can override\nusing the `.groups` argument."
  },
  {
    "objectID": "2_analysis.html#simulation-study-3-further-sensitivity-analysis",
    "href": "2_analysis.html#simulation-study-3-further-sensitivity-analysis",
    "title": "2  Results",
    "section": "2.3 Simulation study 3: Further sensitivity analysis",
    "text": "2.3 Simulation study 3: Further sensitivity analysis\n\ndata_sens_lfc <- readr::read_csv2(file.path(in.dir, \"cases_SIM_SENS_lfc.csv\"))\n\nℹ Using \"','\" as decimal and \"'.'\" as grouping mark. Use `read_delim()` for more control.\n\n\nRows: 800000 Columns: 61\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (10): problem, algorithm, cortype, contrast, alternative, adjustment, tr...\ndbl (50): job.id, nrep, n, prev, m, se, sp, L, rhose, rhosp, benchmark, alph...\nlgl  (1): random\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndata_sens_lfc <- data_sens_lfc %>%\n  mutate(Adjustment = recode_factor(\n    interaction(adjustment, pars, drop = TRUE),\n    \"none.list()\" = \"none\",\n    \"bonferroni.list()\"=\"Bonferroni\", \n    \"maxt.list()\" = \"maxT\",\n    \"mbeta.list()\" = \"mBeta (lfc_pr=1)\",\n    \"mbeta.list(lfc_pr=0.5)\" = \"mBeta (lfc_pr=0.5)\",\n    \"mbeta.list(lfc_pr=0)\" = \"mBeta (lfc_pr=0)\",\n    \"bootstrap.list(type='wild')\" = \"Bootstrap (wild)\",\n    \"bootstrap.list()\" = \"Bootstrap (pairs)\") \n  )\n\ndim(data_sens_lfc)\n\n[1] 800000     62\n\n\n\ndata_sens_roc <- readr::read_csv2(file.path(in.dir, \"cases_SIM_SENS_roc.csv\"))\n\nℹ Using \"','\" as decimal and \"'.'\" as grouping mark. Use `read_delim()` for more control.\n\n\nRows: 800000 Columns: 62\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (11): problem, algorithm, auc, dist, contrast, alternative, adjustment, ...\ndbl (50): job.id, nrep, n, prev, m, rhose, e, k, delta, rhosp, benchmark, al...\nlgl  (1): random\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndata_sens_roc <- data_sens_roc %>%\n  mutate(Adjustment = recode_factor(\n    interaction(adjustment, pars, drop = TRUE),\n    \"none.list()\" = \"none\",\n    \"bonferroni.list()\"=\"Bonferroni\", \n    \"maxt.list()\" = \"maxT\",\n    \"mbeta.list()\" = \"mBeta (lfc_pr=1)\",\n    \"mbeta.list(lfc_pr=0.5)\" = \"mBeta (lfc_pr=0.5)\",\n    \"mbeta.list(lfc_pr=0)\" = \"mBeta (lfc_pr=0)\",\n    \"bootstrap.list(type='wild')\" = \"Bootstrap (wild)\",\n    \"bootstrap.list()\" = \"Bootstrap (pairs)\") \n  )\n\ndim(data_sens_roc)\n\n[1] 800000     63\n\n\n\n2.3.1 Bi-exponential ROC model\nIn this sensitvity analysis. the data generating ROC\n\ndata_sens_roc %>% \n  filter(n<1000) %>%\n  filter(!(Adjustment %in% c(\"mBeta (lfc_pr=0.5)\", \"mBeta (lfc_pr=0)\"))) %>% \n  group_by(Adjustment, n, prev, m, dist) %>%\n  summarize(nsim=n(), rr = mean(`0` > 0)) %>%\n  ggplot(aes(n, rr, col=dist, fill=dist, pch=dist))+\n  geom_point(size=6, alpha=0.6) +\n  geom_line(size=2, alpha=0.6) +\n  xlab(\"Total sample size\") +\n  ylab(\"FWER\") +\n  owntheme +\n  facet_wrap(~ Adjustment, ncol=1)\n\n`summarise()` has grouped output by 'Adjustment', 'n', 'prev', 'm'. You can\noverride using the `.groups` argument.\n\n\n\n\n\n\n\n2.3.2 Prior influence of mbeta adjustment\nThe mBeta adjustment is a heuristic approach which builds on a Bayesian multivariate Beta-Binomial model. In this sensitivity analysis, the influence of the “lfc_pr’ hyperparameter is investigated. It lies in the unit interval and controls if the prior distribution is solely a least-favorable parameter configuration (lfc_pr=1, default), a mixture distribution (lfc_pr=0.5) or solely a uniform distribution (lfc_pr=0). As we can see below, this parameter has a noticeable influence on operating characteristics as the FWER.\n\ndata_sens_roc %>% \n  filter(n<1000, dist==\"normal\") %>%\n  filter(Adjustment %in% c(\"none\", \"mBeta (lfc_pr=1)\", \"mBeta (lfc_pr=0.5)\", \"mBeta (lfc_pr=0)\", \"Bootstrap (pairs)\")) %>% \n  group_by(Adjustment, n, prev, m, dist) %>%\n  summarize(nsim=n(), rr = mean(`0` > 0)) %>%\n  ggplot(aes(n, rr, col=Adjustment, fill=Adjustment, pch=Adjustment))+\n  geom_point(size=6, alpha=0.6) +\n  geom_line(size=2, alpha=0.6) +\n  xlab(\"Total sample size\") +\n  ylab(\"FWER\") +\n  owntheme \n\n`summarise()` has grouped output by 'Adjustment', 'n', 'prev', 'm'. You can\noverride using the `.groups` argument.\n\n\n\n\n\n\ndata_sens_lfc %>% \n  filter(n<1000, se==0.9) %>%\n  filter(Adjustment %in% c(\"none\", \"mBeta (lfc_pr=1)\", \"mBeta (lfc_pr=0.5)\", \"mBeta (lfc_pr=0)\", \"Bootstrap (pairs)\")) %>% \n  group_by(Adjustment, n, prev, m, se) %>%\n  summarize(nsim=n(), rr = mean(`0` > 0)) %>%\n  ggplot(aes(n, rr, col=Adjustment, fill=Adjustment, pch=Adjustment))+\n  geom_point(size=6, alpha=0.6) +\n  geom_line(size=2, alpha=0.6) +\n  xlab(\"Total sample size\") +\n  ylab(\"FWER\") +\n  owntheme \n\n`summarise()` has grouped output by 'Adjustment', 'n', 'prev', 'm'. You can\noverride using the `.groups` argument."
  },
  {
    "objectID": "2_analysis.html#simulation-study-3-further-sensitivity-analyses",
    "href": "2_analysis.html#simulation-study-3-further-sensitivity-analyses",
    "title": "2  Results",
    "section": "2.3 Simulation study 3: Further sensitivity analyses",
    "text": "2.3 Simulation study 3: Further sensitivity analyses\n\n\nCode\nin.dir &lt;- file.path(\"E:/cases_SIM/cases_SIM_results\") # TODO: remove\n\ndata_sens_lfc &lt;- readr::read_csv2(file.path(in.dir, \"cases_SIM_SENS_lfc.csv\"))\n\n\nℹ Using \"','\" as decimal and \"'.'\" as grouping mark. Use `read_delim()` for more control.\n\n\nRows: 400000 Columns: 61\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (10): problem, algorithm, cortype, contrast, alternative, adjustment, tr...\ndbl (50): job.id, nrep, n, prev, m, se, sp, L, rhose, rhosp, benchmark, alph...\nlgl  (1): random\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\ndata_sens_lfc &lt;- data_sens_lfc %&gt;%\n  mutate(Adjustment = recode_factor(\n    interaction(adjustment, pars, drop = TRUE),\n    \"none.list()\" = \"none\",\n    \"bonferroni.list()\"=\"Bonferroni\", \n    \"maxt.list()\" = \"maxT\",\n    \"mbeta.list()\" = \"mBeta (lfc_pr=1)\",\n    \"mbeta.list(lfc_pr=0.5)\" = \"mBeta (lfc_pr=0.5)\",\n    \"mbeta.list(lfc_pr=0)\" = \"mBeta (lfc_pr=0)\",\n    \"bootstrap.list(type='wild')\" = \"Bootstrap (wild)\",\n    \"bootstrap.list()\" = \"Bootstrap (pairs)\") \n  )\n\ndim(data_sens_lfc)\n\n\n[1] 400000     62\n\n\n\n\nCode\ndata_sens_roc &lt;- readr::read_csv2(file.path(in.dir, \"cases_SIM_SENS_roc.csv\"))\n\n\nℹ Using \"','\" as decimal and \"'.'\" as grouping mark. Use `read_delim()` for more control.\n\n\nRows: 800000 Columns: 62\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (11): problem, algorithm, auc, dist, contrast, alternative, adjustment, ...\ndbl (50): job.id, nrep, n, prev, m, rhose, e, k, delta, rhosp, benchmark, al...\nlgl  (1): random\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\ndata_sens_roc &lt;- data_sens_roc %&gt;%\n  mutate(Adjustment = recode_factor(\n    interaction(adjustment, pars, drop = TRUE),\n    \"none.list()\" = \"none\",\n    \"bonferroni.list()\"=\"Bonferroni\", \n    \"maxt.list()\" = \"maxT\",\n    \"mbeta.list()\" = \"mBeta (lfc_pr=1)\",\n    \"mbeta.list(lfc_pr=0.5)\" = \"mBeta (lfc_pr=0.5)\",\n    \"mbeta.list(lfc_pr=0)\" = \"mBeta (lfc_pr=0)\",\n    \"bootstrap.list(type='wild')\" = \"Bootstrap (wild)\",\n    \"bootstrap.list()\" = \"Bootstrap (pairs)\") \n  )\n\ndim(data_sens_roc)\n\n\n[1] 800000     63\n\n\n\n2.3.1 Bi-exponential ROC model\nIn this sensitvity analysis, the data generating ROC model was altered to the a bi-exponential model instead of the default bi-normal model.\n\n\nCode\ndata_sens_roc %&gt;% \n  filter(n&lt;1000) %&gt;%\n  filter(!(Adjustment %in% c(\"mBeta (lfc_pr=0.5)\", \"mBeta (lfc_pr=0)\"))) %&gt;% \n  group_by(Adjustment, n, prev, m, dist) %&gt;%\n  summarize(nsim=n(), rr = mean(`0` &gt; 0)) %&gt;%\n  ggplot(aes(n, rr, col=dist, fill=dist, pch=dist))+\n  geom_point(size=6, alpha=0.6) +\n  geom_line(size=2, alpha=0.6) +\n  xlab(\"Total sample size\") +\n  ylab(\"FWER\") +\n  geom_hline(yintercept=0.025, col=\"red\", lwd=2, lty=2, alpha=0.75) +\n  owntheme +\n  facet_wrap(~ Adjustment, ncol=2)\n\n\n`summarise()` has grouped output by 'Adjustment', 'n', 'prev', 'm'. You can\noverride using the `.groups` argument.\n\n\n\n\n\nThe next plot presents the same data slighty differently.\n\n\nCode\ndata_sens_roc %&gt;% \n  filter(n&lt;1000) %&gt;%\n  filter(!(Adjustment %in% c(\"mBeta (lfc_pr=0.5)\", \"mBeta (lfc_pr=0)\"))) %&gt;% \n  group_by(Adjustment, n, prev, m, dist) %&gt;%\n  summarize(nsim=n(), rr = mean(`0` &gt; 0)) %&gt;%\n  ggplot(aes(n, rr, col=Adjustment, fill=Adjustment, pch=Adjustment))+\n  geom_point(size=6, alpha=0.6) +\n  geom_line(size=2, alpha=0.6) +\n  xlab(\"Total sample size\") +\n  ylab(\"FWER\") +\n  geom_hline(yintercept=0.025, col=\"red\", lwd=2, lty=2, alpha=0.75) +\n  owntheme +\n  facet_wrap(~ dist, ncol=1)\n\n\n`summarise()` has grouped output by 'Adjustment', 'n', 'prev', 'm'. You can\noverride using the `.groups` argument.\n\n\n\n\n\n\n\n2.3.2 Prior influence of mbeta adjustment\nThe mBeta adjustment is a heuristic approach which builds on a Bayesian multivariate Beta-Binomial model. In this sensitivity analysis, the influence of the “lfc_pr’ hyperparameter is investigated. It lies in the unit interval and controls if the prior distribution is solely a least-favorable parameter configuration (lfc_pr=1, default), a mixture distribution (lfc_pr=0.5) or solely a uniform distribution (lfc_pr=0). As we can see below, this parameter has a noticeable influence on operating characteristics as the FWER.\n\n\nCode\ndata_sens_roc %&gt;% \n  filter(n&lt;1000, dist==\"normal\") %&gt;%\n  filter(Adjustment %in% c(\"none\", \"mBeta (lfc_pr=1)\", \"mBeta (lfc_pr=0.5)\", \"mBeta (lfc_pr=0)\", \"Bootstrap (pairs)\")) %&gt;% \n  group_by(Adjustment, n, prev, m, dist) %&gt;%\n  summarize(nsim=n(), rr = mean(`0` &gt; 0)) %&gt;%\n  ggplot(aes(n, rr, col=Adjustment, fill=Adjustment, pch=Adjustment))+\n  geom_point(size=6, alpha=0.6) +\n  geom_line(size=2, alpha=0.6) +\n  xlab(\"Total sample size\") +\n  ylab(\"FWER\") +\n  geom_hline(yintercept=0.025, col=\"red\", lwd=2, lty=2, alpha=0.75) +\n  owntheme + \n  guides(fill=guide_legend(nrow=2, byrow=TRUE),\n         col=guide_legend(nrow=2, byrow=TRUE),\n         pch=guide_legend(nrow=2, byrow=TRUE))\n\n\n`summarise()` has grouped output by 'Adjustment', 'n', 'prev', 'm'. You can\noverride using the `.groups` argument.\n\n\n\n\n\n\n\nCode\ndata_sens_lfc %&gt;% \n  filter(n&lt;1000, se==0.8) %&gt;%\n  filter(Adjustment %in% c(\"none\", \"mBeta (lfc_pr=1)\", \"mBeta (lfc_pr=0.5)\", \"mBeta (lfc_pr=0)\", \"Bootstrap (pairs)\")) %&gt;% \n  group_by(Adjustment, n, prev, m, se) %&gt;%\n  summarize(nsim=n(), rr = mean(`0` &gt; 0)) %&gt;%\n  ggplot(aes(n, rr, col=Adjustment, fill=Adjustment, pch=Adjustment))+\n  geom_point(size=6, alpha=0.6) +\n  geom_line(size=2, alpha=0.6) +\n  xlab(\"Total sample size\") +\n  ylab(\"FWER\") +\n  geom_hline(yintercept=0.025, col=\"red\", lwd=2, lty=2, alpha=0.75) +\n  owntheme + \n  guides(fill=guide_legend(nrow=2, byrow=TRUE),\n         col=guide_legend(nrow=2, byrow=TRUE),\n         pch=guide_legend(nrow=2, byrow=TRUE))\n\n\n`summarise()` has grouped output by 'Adjustment', 'n', 'prev', 'm'. You can\noverride using the `.groups` argument."
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "cases simulation study",
    "section": "References",
    "text": "References\n\nWestphal, Max, and Antonia Zapf. “Statistical Inference for Diagnostic Test Accuracy Studies with Multiple Comparisons.” arXiv preprint arXiv:2105.13469 (2021)."
  },
  {
    "objectID": "1_implementation.html#software",
    "href": "1_implementation.html#software",
    "title": "1  Implementation",
    "section": "1.1 Software",
    "text": "1.1 Software\nThe cases package provides the direct implementation all the multiple comparison procedures under investigation.\nThe simulation study was conducted with the R package batchtools.\nFor generation of the synthetic binary data, the bindata package was used among others.\nVersion control of employed dependencies is handled via the renv package."
  }
]